{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import keras\n",
    "\n",
    "from keras import Input, regularizers\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut,LeavePGroupsOut\n",
    "from keras.layers import Flatten,Dense,Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)#允许GPU分配的内存随程序需求而增长\n",
    "\n",
    "print(\"Part One,Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取及整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文件读取Step1\n",
    "path='F://data//FAIMS_rats//rat_data//data4//'#path=数据集存放位置\n",
    "Control_File =path+'RAT_Control_Pus_48h_9'#RAT_Control_Pus_48h_9\n",
    "Ecoli_File =path+ 'RAT_Ecoli_Pus_48h_12'\n",
    "Parug_File = path+'RAT_Parug_Pus_48h_10'\n",
    "Saureus_File = path+'RAT_Saureus_Pus_48h_10'\n",
    "\n",
    "#文件读取Step2\n",
    "Control = scio.loadmat(Control_File)\n",
    "Ecoli = scio.loadmat(Ecoli_File)\n",
    "Parug = scio.loadmat(Parug_File)\n",
    "Saureus = scio.loadmat(Saureus_File)\n",
    "#print(Control.keys())\n",
    "\n",
    "#感染数据获取\n",
    "data_Control =Control.get('Control_Pus_48h_9')\n",
    "data_Ecoli =Ecoli.get('Ecoli_Pus_48h_12')\n",
    "data_Parug =Parug.get('Parug_Pus_48h_10')\n",
    "data_Saureus =Saureus.get('Saureus_Pus_48h_10')\n",
    "\n",
    "#小鼠测试样本数读取\n",
    "RatNum_Control=Control.get('Control_Pus_48h_9_RATTUnum')\n",
    "RatNum_Ecoli=Ecoli.get('Ecoli_Pus_48h_12_RATTUnum')\n",
    "RatNum_Parug=Parug.get('Parug_Pus_48h_10_RATTUnum')\n",
    "RatNum_Saureus=Saureus.get('Saureus_Pus_48h_10_RATTUnum')\n",
    "print(len(RatNum_Control))\n",
    "'''\n",
    "[[18 15 18 17 18 21 17 20 19]]\n",
    "[[17 20 18 17 13 17 17 20 18 20 16 19]]\n",
    "[[18 12 23 17 10 18 16 17 19 24]]\n",
    "[[18 26 17 21 24 20 22 19 19 17]]\n",
    "'''\n",
    "RatNum_Control = RatNum_Control.reshape(-1)#降维 for 后续操作\n",
    "RatNum_Ecoli = RatNum_Ecoli.reshape(-1)\n",
    "RatNum_Parug = RatNum_Parug.reshape(-1)\n",
    "RatNum_Saureus = RatNum_Saureus.reshape(-1)\n",
    "\n",
    "#感染标签读取\n",
    "label_Control =Control.get('Control_Pus_48h_9_LABEL')\n",
    "label_Ecoli   =Ecoli.get('Ecoli_Pus_48h_12_LABEL')\n",
    "label_Parug  =Parug.get('Parug_Pus_48h_10_LABEL')\n",
    "label_Saureus =Saureus.get('Saureus_Pus_48h_10_LABEL')\n",
    "print(label_Control.shape)\n",
    "print(label_Ecoli.shape)\n",
    "print(label_Parug.shape)\n",
    "print(label_Saureus.shape)\n",
    "print(\"This is label\\n\\n\")\n",
    "#感染数据替换for reduce class_num（感染标签虽是4个，但max=4，被判为5分类。所有感染标签值-1，max=3，为4分类）\n",
    "label_Control =np.full(label_Control.shape,0)#181\n",
    "label_Ecoli =np.full(label_Ecoli.shape,1)#173\n",
    "label_Parug =np.full(label_Parug.shape,2)#177\n",
    "label_Saureus =np.full(label_Saureus.shape,3)#187\n",
    "\n",
    "\n",
    "#老鼠标签\n",
    "label_rat_Control =Control.get('Control_Pus_48h_9_RATLABEL')\n",
    "label_rat_Ecoli   =Ecoli.get('Ecoli_Pus_48h_12_RATLABEL')\n",
    "label_rat_Parug  =Parug.get('Parug_Pus_48h_10_RATLABEL')\n",
    "label_rat_Saureus =Saureus.get('Saureus_Pus_48h_10_RATLABEL')\n",
    "#老鼠标签整理for loo\n",
    "label_rat_Control_added = np.full(label_rat_Control.shape,-1)\n",
    "label_rat_Ecoli_added = np.full(label_rat_Ecoli.shape,8)\n",
    "label_rat_Parug_added =np.full(label_rat_Parug.shape,20)\n",
    "label_rat_Saureus_added =np.full(label_rat_Saureus.shape,30)\n",
    "\n",
    "label_rat_Control = label_rat_Control +label_rat_Control_added\n",
    "label_rat_Ecoli = label_rat_Ecoli +label_rat_Ecoli_added\n",
    "label_rat_Parug = label_rat_Parug +label_rat_Parug_added\n",
    "label_rat_Saureus = label_rat_Saureus +label_rat_Saureus_added\n",
    "#print(label_rat_Parug)\n",
    "\n",
    "#数据、感染标签、小鼠标签整和\n",
    "total_data_combat =np.concatenate([data_Control,data_Ecoli,data_Parug,data_Saureus],axis=2)#(102, 512, 718)\n",
    "total_label_combat =np.concatenate([label_Control,label_Ecoli,label_Parug,label_Saureus])#(718,1)\n",
    "total_label_rat_combat =np.concatenate([label_rat_Control,label_rat_Ecoli,label_rat_Parug,label_rat_Saureus])#(718,1)\n",
    "total_rat_num = np.concatenate([RatNum_Control,RatNum_Ecoli,RatNum_Parug,RatNum_Saureus],axis=0).reshape(41)\n",
    "\n",
    "print(total_data_combat.shape)\n",
    "print(total_label_rat_combat.shape)\n",
    "print(total_label_rat_combat.shape)\n",
    "print(\"Part Two,Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统一老鼠的样本个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##冗余样本删除\n",
    "\n",
    "#记录每个老鼠出现次数的数组\n",
    "rat_times=np.zeros(41)\n",
    "\n",
    "#冗余样本位置获取\n",
    "redundant=np.zeros(752)\n",
    "j=0\n",
    "for i in range(752):\n",
    "    rat_this = total_label_rat_combat[i]\n",
    "    rat_times[rat_this]+=1\n",
    "    if rat_times[rat_this]>15:\n",
    "        redundant[j]=i\n",
    "        j+=1\n",
    "redundant = np.unique(redundant,axis = 0)\n",
    "redundant =np.delete(redundant,[0],axis=0)\n",
    "#print(redundant)#冗余样本位置\n",
    "#删除\n",
    "total_data_EP_ori=np.delete(total_data_combat,redundant,axis=2)\n",
    "total_label_EP_ori=np.delete(total_label_combat,redundant,axis=0)\n",
    "total_label_rat_EP_ori=np.delete(total_label_rat_combat,redundant,axis=0)\n",
    "#print(total_data_EP_ori.shape,total_label_EP_ori.shape)#冗余样本删除后的数组\n",
    "\n",
    "\n",
    "##缺少样本补足\n",
    "\n",
    "#data数组补足\n",
    "data_patch_EP_13 = total_data_EP_ori[:,:,206:208]\n",
    "data_patch_EP_12 = total_data_EP_ori[:,:,337:340]\n",
    "data_patch_EP_10 = total_data_EP_ori[:,:,375:380]\n",
    "\n",
    "total_data_EP_13_1=total_data_EP_ori[:,:,0:208]\n",
    "total_data_EP_13_2=total_data_EP_ori[:,:,208:]\n",
    "total_data_EP_13= np.concatenate([total_data_EP_13_1,data_patch_EP_13,total_data_EP_13_2],axis=2)\n",
    "\n",
    "total_data_EP_12_1=total_data_EP_13[:,:,0:342]\n",
    "total_data_EP_12_2=total_data_EP_13[:,:,342:]\n",
    "total_data_EP_12= np.concatenate([total_data_EP_12_1,data_patch_EP_12,total_data_EP_12_2],axis=2)\n",
    "\n",
    "total_data_EP_10_1=total_data_EP_12[:,:,0:385]\n",
    "total_data_EP_10_2=total_data_EP_12[:,:,385:]\n",
    "total_data_EP_10= np.concatenate([total_data_EP_10_1,data_patch_EP_10,total_data_EP_10_2],axis=2)\n",
    "total_data_EP=total_data_EP_10\n",
    "\n",
    "#label数组补足\n",
    "label_patch_EP_13 = total_label_EP_ori[206:208]\n",
    "label_patch_EP_12 = total_label_EP_ori[337:340]\n",
    "label_patch_EP_10 = total_label_EP_ori[375:380]\n",
    "\n",
    "total_label_EP_13_1=total_label_EP_ori[0:208]\n",
    "total_label_EP_13_2=total_label_EP_ori[208:]\n",
    "total_label_EP_13= np.concatenate([total_label_EP_13_1,label_patch_EP_13,total_label_EP_13_2],axis=0)\n",
    "\n",
    "total_label_EP_12_1=total_label_EP_13[0:342]\n",
    "total_label_EP_12_2=total_label_EP_13[342:]\n",
    "total_label_EP_12= np.concatenate([total_label_EP_12_1,label_patch_EP_12,total_label_EP_12_2],axis=0)\n",
    "\n",
    "total_label_EP_10_1=total_label_EP_12[0:385]\n",
    "total_label_EP_10_2=total_label_EP_12[385:]\n",
    "total_label_EP_10= np.concatenate([total_label_EP_10_1,label_patch_EP_10,total_label_EP_10_2],axis=0)\n",
    "total_label_EP=total_label_EP_10\n",
    "\n",
    "#老鼠样本个数补足\n",
    "rat_patch_EP_13 = total_label_rat_EP_ori[206:208]\n",
    "rat_patch_EP_12 = total_label_rat_EP_ori[337:340]\n",
    "rat_patch_EP_10 = total_label_rat_EP_ori[375:380]\n",
    "\n",
    "total_rat_EP_13_1=total_label_rat_EP_ori[0:208]\n",
    "total_rat_EP_13_2=total_label_rat_EP_ori[208:]\n",
    "total_rat_EP_13= np.concatenate([total_rat_EP_13_1,rat_patch_EP_13,total_rat_EP_13_2],axis=0)\n",
    "\n",
    "total_rat_EP_12_1=total_rat_EP_13[0:342]\n",
    "total_rat_EP_12_2=total_rat_EP_13[342:]\n",
    "total_rat_EP_12= np.concatenate([total_rat_EP_12_1,rat_patch_EP_12,total_rat_EP_12_2],axis=0)\n",
    "\n",
    "total_rat_EP_10_1=total_rat_EP_12[0:385]\n",
    "total_rat_EP_10_2=total_rat_EP_12[385:]\n",
    "total_rat_EP_10= np.concatenate([total_rat_EP_10_1,rat_patch_EP_10,total_rat_EP_10_2],axis=0)\n",
    "total_rat_EP=total_rat_EP_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#维度处理（102,512,total_num）-->（total_num,102,512,1）\n",
    "total_num = 615\n",
    "total_data_change = np.swapaxes(total_data_EP,0,2)\n",
    "total_data_change_change = np.swapaxes(total_data_change,1,2)#(718, 102, 512)\n",
    "print(total_data_change_change.shape)\n",
    "total_data_expend = np.expand_dims(total_data_change_change, axis=3)\n",
    "\n",
    "#图片剪裁（total_num,102,512,1）-->(total_num,102,170,1)\n",
    "total_data_cut = total_data_expend[:,:,150:320,:]\n",
    "scaler = StandardScaler()\n",
    "total_data_norm = scaler.fit_transform(total_data_cut.astype(np.float32).reshape(-1, 102*170)).reshape(-1, 102, 170,1)\n",
    "\n",
    "#Final_data\n",
    "total_data = np.concatenate([total_data_norm,total_data_norm,total_data_norm],axis=3)\n",
    "total_label = total_label_EP.reshape(total_num)\n",
    "total_label_rat = total_rat_EP.reshape(total_num)\n",
    "print(total_data.shape)\n",
    "print(total_label.shape)\n",
    "print(total_label_rat.shape)\n",
    "print(\"Part Three,Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_recompile():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False,\n",
    "                                      input_shape=(102, 170, 3), \n",
    "                                      pooling='max'\n",
    "                           )#基础模型\n",
    "\n",
    "    ResNet50_LAYERS_TO_FREEZE = 'res5b_branch2c'#模型冻结至该层    \n",
    "    set_trainable = False\n",
    "    for layer in base_model.layers:\n",
    "        if layer.name == ResNet50_LAYERS_TO_FREEZE:\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    model =keras.Sequential()#使用Sequential()在resnet后添加网络层\n",
    "    model.add(base_model)\n",
    "    model.add(Dense(512,activation='relu', kernel_regularizer = regularizers.l2 (0.01)))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                    optimizer =keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-06),\n",
    "                    metrics =['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 留一法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由于内存不足，一个子集的老鼠进行留一法需要分两次，分别保存为003,004.\n",
    "\n",
    "fea_resnet = np.zeros(615)#保存提取出的特征\n",
    "rat_now = 0#当前运行到第几只老鼠\n",
    "lpgo = LeavePGroupsOut(n_groups=1)\n",
    "\n",
    "for(train_index,test_index) in lpgo.split(total_data,groups=total_label_rat):\n",
    "    if rat_now >=0 :#从第time只老鼠开始。（time_min==0）\n",
    "        print(\"第\",rat_now,\"次留一法\\n\\n\\n\")\n",
    "        train_num, test_num = train_index.shape, test_index.shape\n",
    "        X_train, X_test = total_data[train_index], total_data[test_index]\n",
    "        y_train, y_test = total_label[train_index],total_label[test_index]#训练集，测试集数据\n",
    "        model =model_recompile()#模型重编译                      \n",
    "        \n",
    "        model.fit(X_train,y_train,epochs=20,validation_data=(X_test,y_test),batch_size=8,verbose = 2)#模型训练\n",
    "        features = model.predict(X_test,batch_size =3)#输出分类概率\n",
    "        if(rat_now==0 or rat_now==20):\n",
    "            fea_resnet=features\n",
    "        else:\n",
    "            fea_resnet=np.concatenate([fea_resnet,features])#ResNet深度特征整合\n",
    "        print(features)\n",
    "    rat_now+=1 \n",
    "        #print(loss,accuracy)\n",
    "\n",
    "print(\"model\",1,\"-----------------------------------------------------------\\n\\n\\n\")  \n",
    "\n",
    "#ResNet深度特征本地保存\n",
    "np.savetxt('003',fea_resnet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
